Year,Sources,Name,Authors,First Author,Chinese/English,Abstract,Venues,doi,Citation,Id,Keywords
2021,IEEE Transactions on Visualization and Computer Graphics,Composition and configuration patterns in multiple-view visualizations,"Xi Chen, Wei Zeng, Yanna Lin, Hayder Mahdi Ai-Maneea, Jonathan Roberts, Remco Chang",Xi Chen,English,"Multiple-view visualization (MV) is a layout design technique often employed to help users see a large number of data attributes and values in a single cohesive representation. Because of its generalizability, the MV design has been widely adopted by the visualization community to help users examine and interact with large, complex, and high-dimensional data. However, although ubiquitous, there has been little work to categorize and analyze MVs in order to better understand its design space. As a result, there has been little to no guideline in how to use the MV design effectively. In this paper, we present an in-depth study of how MVs are designed in practice. We focus on two fundamental measures of multiple-view patterns: composition, which quantifies what view types and how many are there; and configuration, which characterizes spatial arrangement of view layouts in the display space. We build a new?бн",Article,https://ieeexplore.ieee.org/abstract/document/9222323/,97,chen2020composition,"Multiple views, design pattern, quantitative analysis, example-based design"
2020,IEEE transactions on visualization and computer graphics,Topology density map for urban data visualization and analysis,"Zezheng Feng, Haotian Li, Wei Zeng, Shuang-Hua Yang, Huamin Qu",Zezheng Feng,English,"Density map is an effective visualization technique for depicting the scalar field distribution in 2D space. Conventional methods for constructing density maps are mainly based on Euclidean distance, limiting their applicability in urban analysis that shall consider road network and urban traffic. In this work, we propose a new method named Topology Density Map, targeting for accurate and intuitive density maps in the context of urban environment. Based on the various constraints of road connections and traffic conditions, the method first constructs a directed acyclic graph (DAG) that propagates nonlinear scalar fields along 1D road networks. Next, the method extends the scalar fields to a 2D space by identifying key intersecting points in the DAG and calculating the scalar fields for every point, yielding a weighted Voronoi diagram like effect of space division. Two case studies demonstrate that the Topology Density?бн",Article,https://ieeexplore.ieee.org/abstract/document/9222248/,36,feng2020topology,"Density map, network topology, urban data"
2020,IEEE Transactions on Visualization and Computer Graphics,Revisiting the modifiable areal unit problem in deep traffic prediction with visual analytics,"Wei Zeng, Chengqiao Lin, Juncong Lin, Jincheng Jiang, Jiazhi Xia, Cagatay Turkay, Wei Chen",Wei Zeng,English,"Deep learning methods are being increasingly used for urban traffic prediction where spatiotemporal traffic data is aggregated into sequentially organized matrices that are then fed into convolution-based residual neural networks. However, the widely known modifiable areal unit problem within such aggregation processes can lead to perturbations in the network inputs. This issue can significantly destabilize the feature embeddings and the predictions - rendering deep networks much less useful for the experts. This paper approaches this challenge by leveraging unit visualization techniques that enable the investigation of many-to-many relationships between dynamically varied multi-scalar aggregations of urban traffic data and neural network predictions. Through regular exchanges with a domain expert, we design and develop a visual analytics solution that integrates 1) a  Bivariate Map  equipped with an?бн",Article,https://ieeexplore.ieee.org/abstract/document/9228894/,35,zeng2020revisiting,"MAUP, traffic prediction, deep learning, model diagnostic, visual analytics"
2020,2020 IEEE Pacific visualization symposium (PacificVis),Visual interpretation of recurrent neural network on multi-dimensional time-series forecast,"Qiaomu Shen, Yanhong Wu, Yuzhe Jiang, Wei Zeng, KH Alexis, Anna Vianova, Huamin Qu",Qiaomu Shen,English,"Recent attempts at utilizing visual analytics to interpret Recurrent Neural Networks (RNNs) mainly focus on natural language processing (NLP) tasks that take symbolic sequences as input. However, many real-world problems like environment pollution forecasting apply RNNs on sequences of multi-dimensional data where each dimension represents an individual feature with semantic meaning such as PM 2.5  and SO 2 . RNN interpretation on multi-dimensional sequences is challenging as users need to analyze what features are important at different time steps to better understand model behavior and gain trust in prediction. This requires effective and scalable visualization methods to reveal the complex many-to-many relations between hidden units and features. In this work, we propose a visual analytics system to interpret RNNs on multi-dimensional time-series forecasts. Specifically, to provide an overview to?бн",Conference paper,https://ieeexplore.ieee.org/abstract/document/9086238/,34,shen2020visual,"interpretable machine learning, recurrent neural networks, multi-dimensional time series, air pollutant forecast"
2021,Journal of visualization,VIStory: interactive storyboard for exploring visual information in scientific publications,"Wei Zeng, Ao Dong, Xi Chen, Zhang-lin Cheng",Wei Zeng,English,"Many visual analytics have been developed for examining scientific publications comprising wealthy data such as authors and citations. The studies provide unprecedented insights on a variety of applications, e.g., literature review and collaboration analysis. However, visual information (i.e., figures) that are widely employed for storytelling and methods description are often neglected. We present VIStory, an interactive storyboard for exploring visual information in scientific publications. We harvest the data using an automatic figure extraction method, resulting in a large corpora of figures. Each figure contains various attributes such as dominant color and width/height ratio, together with faceted metadata of the publication including venues, authors, and keywords. To depict these information, we develop an intuitive interface consisting of three components: 1) Faceted View enables efficient query by publication?бн",Article,https://dl.acm.org/doi/abs/10.1145/3356422.3356430,27,dong2019vistory,"visualization survey, document visualization, image browser, faceted
metadata"
2022,IEEE Transactions on Visualization and Computer Graphics,VISAtlas: An image-based exploration and query system for large visualization collections via neural image embedding,"Yilin Ye, Rong Huang, Wei Zeng",Yilin Ye,English,"High-quality visualization collections are beneficial for a variety of applications including visualization reference and data-driven visualization design. The visualization community has created many visualization collections, and developed interactive exploration systems for the collections. However, the systems are mainly based on extrinsic attributes like authors and publication years, whilst neglect intrinsic property ( i.e ., visual appearance) of visualizations, hindering visual comparison and query of visualization designs. This paper presents  VISAtlas , an image-based approach empowered by neural image embedding, to facilitate exploration and query for visualization collections. To improve embedding accuracy, we create a comprehensive collection of synthetic and real-world visualizations, and use it to train a convolutional neural network (CNN) model with a triplet loss for taxonomical classification of?бн",Article,https://ieeexplore.ieee.org/abstract/document/9984953/,23,ye2022visatlas,"Visualization collection, image embedding, visual query, image visualization, design pattern"
2022,IEEE Transactions on Visualization and Computer Graphics,Deep Colormap Extraction from Visualizations,"Lin-Ping Yuan, Wei Zeng, Siwei Fu, Zhiliang Zeng, Haotian Li, Chi-Wing Fu, Huamin Qu",Lin-Ping Yuan,English,"This article presents a new approach based on deep learning to automatically extract colormaps from visualizations. After summarizing colors in an input visualization image as a Lab color histogram, we pass the histogram to a pre-trained deep neural network, which learns to predict the colormap that produces the visualization. To train the network, we create a new dataset of   64K visualizations that cover a wide variety of data distributions, chart types, and colormaps. The network adopts an atrous spatial pyramid pooling module to capture color features at multiple scales in the input color histograms. We then classify the predicted colormap as discrete or continuous, and refine the predicted colormap based on its color histogram. Quantitative comparisons to existing methods show the superior performance of our approach on both synthetic and real-world visualizations. We further demonstrate the utility of our?бн",Article,https://www.sciencedirect.com/science/article/pii/S0097849321001370,22,yuan2021deep,"Color extraction, information visualization, deep learning, color histogram"
2021,Computers & Graphics 99,UrbanVR: An immersive analytics system for context-aware urban design,"Chi Zhang, Wei Zeng, Ligang Liu",Chi Zhang,English,"Urban design is a highly visual discipline that requires visualization for informed decision making. However, traditional urban design tools are mostly limited to representations on 2D displays that lack intuitive awareness. The popularity of head-mounted displays (HMDs) promotes a promising alternative with consumer-grade 3D displays. We introduce UrbanVR, an immersive analytics system with effective visualization and interaction techniques, to enable architects to assess designs in a virtual reality (VR) environment. Specifically, UrbanVR incorporates 1) a customized parallel coordinates plot (PCP) design to facilitate quantitative assessment of high-dimensional design metrics, 2) a series of egocentric interactions, including gesture interactions and handle-bar metaphors, to facilitate user interactions, and 3) a viewpoint optimization algorithm to help users explore both the PCP for quantitative analysis, and?бн",Article,https://ieeexplore.ieee.org/abstract/document/9395231/,22,zhang2021urbanvr,None
2021,IEEE Transactions on Visualization and Computer Graphics,ActFloor-GAN: activity-guided adversarial networks for human-centric floorplan design,"Shidong Wang, Wei Zeng, Xi Chen, Yu Ye, Yu Qiao, Chi-Wing Fu",Shidong Wang,English,"We present a novel two-stage approach for automated floorplan design in residential buildings with a given exterior wall boundary. Our approach has the unique advantage of being human-centric, that is, the generated floorplans can be geometrically plausible, as well as topologically reasonable to enhance resident interaction with the environment. From the input boundary, we first synthesize a human-activity map that reflects both the spatial configuration and human-environment interaction in an architectural space. We propose to produce the human-activity map either automatically by a pre-trained generative adversarial network (GAN) model, or semi-automatically by synthesizing it with user manipulation of the furniture. Second, we feed the human-activity map into our deep framework  ActFloor-GAN  to guide a pixel-wise prediction of room types. We adopt a re-formulated cycle-consistency constraint in?бн",Article,https://ieeexplore.ieee.org/abstract/document/9609576/,20,wang2021actfloor,"Floorplan design, room layout, human-centric, GAN"
2022,IEEE Transactions on Visualization and Computer Graphics,Effects of view layout on situated analytics for multiple-view representations in immersive visualization,"Zhen Wen, Wei Zeng, Luoxuan Weng, Yihan Liu, Mingliang Xu, Wei Chen",Zhen Wen,English,"Multiple-view (MV) representations enabling multi-perspective exploration of large and complex data are often employed on 2D displays. The technique also shows great potential in addressing complex analytic tasks in immersive visualization. However, although useful, the design space of MV representations in immersive visualization lacks in deep exploration. In this paper, we propose a new perspective to this line of research, by examining the effects of view layout for MV representations on situated analytics. Specifically, we disentangle situated analytics in perspectives of  situatedness  regarding spatial relationship between visual representations and physical referents, and  analytics  regarding cross-view data analysis including filtering, refocusing, and connecting tasks. Through an in-depth analysis of existing layout paradigms, we summarize design trade-offs for achieving high situatedness and effective?бн",Article,https://ieeexplore.ieee.org/abstract/document/9904883/,17,wen2022effects,"Situated analytics, multiple-view representations, view layout, immersive visualization"
2020,2020 29th International Conference on Computer Communications and Networks?бн,SD-seq2seq: a deep learning model for bus bunching prediction based on smart card data,"Zengyang Gong, Bo Du, Zhidan Liu, Wei Zeng, Pascal Perez, Kaishun Wu",Zengyang Gong,English,"Bus bunching, a phenomenon due to the failure of headway or timetable adherence, often causes low level of public transit service with poor bus on-time performance and excessive passenger waiting time. To mitigate bus bunching, an accurate and real-time prediction method plays an important role. In this paper, we propose a supply-demand seq2seq model called SD-seq2seq to predict bus bunching using smart card data. Features from both supply and demand sides of bus service are taken into account, like bus stop type, dwelling time, passenger demand and type, and so on. Extensive experiments on multiple bus routes in real world demonstrate that our method outperforms other baseline methods. The proposed method is expected to provide useful online information of bus operation to both bus operators and passengers.",Conference paper,https://ieeexplore.ieee.org/abstract/document/9209686/,17,gong2020sd,"Bus bunching, seq2seq, Deep learning, Predic- tion, Smart card data, transportation"
2020,IEEE Transactions on Visualization and Computer Graphics,Exemplar-based layout fine-tuning for node-link diagrams,"Jiacheng Pan, Wei Chen, Xiaodong Zhao, Shuyue Zhou, Wei Zeng, Minfeng Zhu, Jian Chen, Siwei Fu, Yingcai Wu",Jiacheng Pan,English,"We design and evaluate a novel layout fine-tuning technique for node-link diagrams that facilitates exemplar-based adjustment of a group of substructures in batching mode. The key idea is to transfer user modifications on a local substructure to other substructures in the entire graph that are topologically similar to the exemplar. We first precompute a canonical representation for each substructure with node embedding techniques and then use it for on-the-fly substructure retrieval. We design and develop a light-weight interactive system to enable intuitive adjustment, modification transfer, and visual graph exploration. We also report some results of quantitative comparisons, three case studies, and a within-participant user study.",Article,https://ieeexplore.ieee.org/abstract/document/9240072/,15,pan2020exemplar,None
2020,IEEE Transactions on Image Processing 29,Deep recognition of vanishing-point-constrained building planes in urban street views,"Zhiliang Zeng, Mengyang Wu, Wei Zeng, Chi-Wing Fu",Zhiliang Zeng,English,"This paper presents a new approach to recognizing vanishing-point-constrained building planes from a single image of street view. We first design a novel convolutional neural network (CNN) architecture that generates geometric segmentation of per-pixel orientations from a single street-view image. The network combines two-stream features of general visual cues and surface normals in gated convolution layers, and employs a deeply supervised loss that encapsulates multi-scale convolutional features. Our experiments on a new benchmark with fine-grained plane segmentations of real-world street views show that our network outperforms state-of-the-arts methods of both semantic and geometric segmentation. The pixel-wise segmentation exhibits coarse boundaries and discontinuities. We then propose to rectify the pixel-wise segmentation into perspectively-projected quads based on spatial proximity between?бн",Article,https://ieeexplore.ieee.org/abstract/document/9068429/,13,zeng2020deep,"Image segmentation, plane reconstruction, aug- mented reality, geometric reasoning, vanishing point, street view"
2021,IEEE Transactions on Knowledge and Data Engineering,Modeling spatial nonstationarity via deformable convolutions for deep traffic flow prediction,"Wei Zeng, Chengqiao Lin, Kang Liu, Juncong Lin, Anthony KH Tung",Wei Zeng,English,"Deep neural networks are being increasingly used for short-term traffic flow prediction, which can be generally categorized as convolutional (CNNs) or graph neural networks (GNNs). CNNs are preferable for region-wise traffic prediction by taking advantage of localized spatial correlations, whilst GNNs achieves better performance for graph-structured traffic data. When applied to region-wise traffic prediction, CNNs typically partition an underlying territory into grid-like spatial units, and employ standard convolutions to learn spatial dependence among the units. However, standard convolutions with fixed geometric structures cannot fully model the nonstationary characteristics of local traffic flows. To overcome the deficiency, we introduce deformable convolution that augments the spatial sampling locations with additional offsets, to enhance the modeling capability of spatial nonstationarity. On this basis, we design a?бн",Article,https://ieeexplore.ieee.org/abstract/document/9540306/,11,zeng2021modeling,"Traffic flow prediction, spatial nonstationarity, deformable convolution, deep learning"
2023,IEEE Transactions on Visualization and Computer Graphics,Let the chart spark: Embedding semantic context into chart with text-to-image generative model,"Shishi Xiao, Suizi Huang, Yue Lin, Yilin Ye, Wei Zeng",Shishi Xiao,English,"Pictorial visualization seamlessly integrates data and semantic context into visual representation, conveying complex information in an engaging and informative manner. Extensive studies have been devoted to developing authoring tools to simplify the creation of pictorial visualizations. However, mainstream works follow a retrieving-and-editing pipeline that heavily relies on retrieved visual elements from a dedicated corpus, which often compromise data integrity. Text-guided generation methods are emerging, but may have limited applicability due to their predefined entities. In this work, we propose  ChartSpark , a novel system that embeds semantic context into chart based on text-to-image generative models.  ChartSpark  generates pictorial visualizations conditioned on both semantic context conveyed in textual inputs and data information embedded in plain charts. The method is generic for both foreground?бн",Article,https://ieeexplore.ieee.org/abstract/document/10296520/,10,xiao2023let,"pictorial visualization, generative model, authoring tool"
2023,ACM transactions on computer-human interaction,Creative and progressive interior color design with eye-tracked user preference,"Shihui Guo, Yubin Shi, Pintong Xiao, Yinan Fu, Juncong Lin, Wei Zeng, Tong-Yee Lee",Shihui Guo,English,"Interior scene colorization is vastly demanded in areas such as personalized architecture design. Existing works either require manual efforts to colorize individual objects or conform to fixed color patterns automatically learned from prior knowledge, whilst neglecting user preference. Quantitatively identifying user preferences is challenging, particularly at the early stage of the design process. The 3D setup also presents new challenges as the inhabitant can observe from any possible viewpoint. We propose a representative view selection method based on visual attention and a progressive preference inference model. We particularly focus on the progressive integration of eye-tracked user preference, which enables the assistance in creativity support and allows the possibility of convergent thinking. A series of user studies have been conducted to validate the effectiveness of the proposed view selection method?бн",Article,https://dl.acm.org/doi/abs/10.1145/3542922,10,guo2023creative,"Interior color design, user preference, creativity support"
2022,Computers & Graphics 105,Saliency-aware color harmony models for outdoor signboard,"Yanna Lin, Wei Zeng, Yu Ye, Huamin Qu",Yanna Lin,English,"This paper introduces a geometric approach for assessing color harmony of a signboard, and color coherence of a signboard with the environment. We propose to incorporate visual saliency as an inherent color characteristic residing in the image space, to better cope with the attention mechanism when people view a scene. In doing so, our color harmony models consider saliency-weighted color differences and area balance in CIELab color space. We collect 5.2?K valid subjective ratings on 375 diverse signboards in the real world, and translate them into quantitative measures for model construction. Experimental results show that our models improve the overall performance, especially for modeling color coherence between a signboard and the environment. The study also reveals that color combinations with similar chroma but distinctive lightness lead to harmonic signboards, while simple color patches in?бн",Article,https://www.sciencedirect.com/science/article/pii/S0097849322000644,7,lin2022saliency,None
2021,Journal of Visualization,Modeling layout design for multiple-view visualization via Bayesian inference,"Lingdan Shao, Zhe Chu, Xi Chen, Yanna Lin, Wei Zeng",Lingdan Shao,English,"Layout design for multiple-view visualization (MV) concerns primarily how to arrange views in layouts that are geometrically and topologically plausible. Guidelines for MV layout design suggest considerations on various design factors, including view (e.g., bar and line charts), viewport (e.g., mobile vs. desktop), and coordination (e.g., exploration vs. comparison), along with expertise and preference of the designer. Recent studies have revealed the diverse space of MV layout design via statistical analysis on empirical MVs, yet neglect the effects of those design factors. To address the gap, this work proposes to model the effects of design factors on MV layouts via Bayesian probabilistic inference. Specifically, we access three important properties of MV layout, i.e., maximum area ratio and weighted average aspect ratio as geometric metrics, and layout topology as a topological metric. We update the posterior?бн",Article,https://link.springer.com/article/10.1007/s12650-021-00781-z,7,shao2021modeling,"Multiple-view visualization, Layout design, Bayesian inference"
2023,IEEE Transactions on Visualization and Computer Graphics,Semi-automatic layout adaptation for responsive multiple-view visualization design,"Wei Zeng, Xi Chen, Yihan Hou, Lingdan Shao, Zhe Chu, Remco Chang",Wei Zeng,English,"Multiple-view (MV) visualizations have become ubiquitous for visual communication and exploratory data visualization. However, most existing MV visualizations are designed for the desktop, which can be unsuitable for the continuously evolving displays of varying screen sizes. In this paper, we present a two-stage adaptation framework that supports the automated retargeting and semi-automated tailoring of a desktop MV visualization for rendering on devices with displays of varying sizes. First, we cast layout retargeting as an optimization problem and propose a simulated annealing technique that can automatically preserve the layout of multiple views. Second, we enable fine-tuning for the visual appearance of each view, using a rule-based auto configuration method complemented with an interactive interface for chart-oriented encoding adjustment. To demonstrate the feasibility and expressivity of our?бн",Article,https://ieeexplore.ieee.org/abstract/document/10029921/,5,zeng2023semi,"Multiple-view visualization, responsive design, layout adaptation, mobile devices"
2023,Computer Graphics Forum,WYTIWYR: A User Intentй\Aware Framework with Multiй\modal Inputs for Visualization Retrieval,"Shishi Xiao, Yihan Hou, Cheng Jin, Wei Zeng",Shishi Xiao,English," Retrieving charts from a large corpus is a fundamental task that can benefit numerous applications such as visualization recommendations. The retrieved results are expected to conform to both explicit visual attributes (e.g., chart type, colormap) and implicit user intents (e.g., design style, context information) that vary upon application scenarios. However, existing exampleй\based chart retrieval methods are built upon nonй\decoupled and lowй\level visual features that are hard to interpret, while definitionй\based ones are constrained to preй\defined attributes that are hard to extend. In this work, we propose a new framework, namely WYTIWYR (Whatй\Youй\Thinkй\Isй\Whatй\Youй\Retrieve), that integrates user intents into the chart retrieval process. The framework consists of two stages: first, the Annotation stage disentangles the visual attributes within the query chart; and second, the Retrieval stage embeds the user's?бн",Article,https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14832,4,xiao2023wytiwyr,None
2024,arXiv preprint arXiv:2401.11923,VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance through Large Language Models,"Zhan Wang, Linping Yuan, Liangwei Wang, Bingchuan Jiang, Wei Zeng",Zhan Wang,English,"Tour guidance in virtual museums encourages multi-modal interactions to boost user experiences, concerning engagement, immersion, and spatial awareness. Nevertheless, achieving the goal is challenging due to the complexity of comprehending diverse user needs and accommodating personalized user preferences. Informed by a formative study that characterizes guidance-seeking contexts, we establish a multi-modal interaction design framework for virtual tour guidance. We then design VirtuWander, a two-stage innovative system using domain-oriented large language models to transform user inquiries into diverse guidance-seeking contexts and facilitate multi-modal interactions. The feasibility and versatility of VirtuWander are demonstrated with virtual guiding examples that encompass various touring scenarios and cater to personalized preferences. We further evaluate VirtuWander through a user study?бн",Article,https://dl.acm.org/doi/abs/10.1145/3613904.3642235,3,wang2024virtuwander,None
2021,IEEE Transactions on Image Processing 30,FloorLevel-Net: recognizing floor-level lines with height-attention-guided multi-task learning,"Mengyang Wu, Wei Zeng, Chi-Wing Fu",Mengyang Wu,English,"The ability to recognize the position and order of the floor-level lines that divide adjacent building floors can benefit many applications, for example, urban augmented reality (AR). This work tackles the problem of locating floor-level lines in street-view images, using a supervised deep learning approach. Unfortunately, very little data is available for training such a network - current street-view datasets contain either semantic annotations that lack geometric attributes, or rectified facades without perspective priors. To address this issue, we first compile a new dataset and develop a new data augmentation scheme to synthesize training samples by harassing (i) the rich semantics of existing rectified facades and (ii) perspective priors of buildings in diverse street views. Next, we design FloorLevel-Net, a multi-task learning network that associates explicit features of building facades and implicit floor-level lines, along with?бн",Article,https://ieeexplore.ieee.org/abstract/document/9494284/,3,wu2021floorlevel,"Multi-task learning, attention mechanism, semantic segmentation, street view, augmented reality"
2024,Proceedings of the CHI Conference on Human Factors in Computing Systems,C2Ideas: Supporting Creative Interior Color Design Ideation with a Large Language Model,"Yihan Hou, Manling Yang, Hao Cui, Lei Wang, Jie Xu, Wei Zeng",Yihan Hou,English," Interior color design is a creative process that endeavors to allocate colors to furniture and other elements within an interior space. While much research focuses on generating realistic interior designs, these automated approaches often misalign with user intention and disregard design rationales. Informed by a need-finding preliminary study, we develop C2Ideas, an innovative system for designers to creatively ideate color schemes enabled by an intent-aligned and domain-oriented large language model. C2Ideas integrates a three-stage process: Idea Prompting stage distills user intentions into color linguistic prompts; Word-Color Association stage transforms the prompts into semantically and stylistically coherent color schemes; and Interior Coloring stage assigns colors to interior elements complying with design principles. We also develop an interactive interface that enables flexible user refinement and?бн",Conference paper,https://www.sciencedirect.com/science/article/pii/S2468502X24000160,2,hou2024c2ideas,"large language model, color deisgn"
2024,Proceedings of the CHI Conference on Human Factors in Computing Systems,TypeDance: Creating semantic typographic logos from image through personalized generation,"Shishi Xiao, Liangwei Wang, Xiaojuan Ma, Wei Zeng",Shishi Xiao,English," Semantic typographic logos harmoniously blend typeface and imagery to represent semantic concepts while maintaining legibility. Conventional methods using spatial composition and shape substitution are hindered by the conflicting requirement for achieving seamless spatial fusion between geometrically dissimilar typefaces and semantics. While recent advances made AI generation of semantic typography possible, the end-to-end approaches exclude designer involvement and disregard personalized design. This paper presents TypeDance, an AI-assisted tool incorporating design rationales with the generative model for personalized semantic typographic logo design. It leverages combinable design priors extracted from uploaded image exemplars and supports type-imagery mapping at various structural granularity, achieving diverse aesthetic designs with flexible control. Additionally, we instantiate a?бн",Conference paper,https://dl.acm.org/doi/abs/10.1145/3613904.3642224,2,xiao2024typedance,"semantic typography, generative model, personalized design"
2024,Proceedings of the ACM on Human-Computer Interaction,The contemporary art of image search: Iterative user intent expansion via vision-language model,"Yilin Ye, Qian Zhu, Shishi Xiao, Kang Zhang, Wei Zeng",Yilin Ye,English,"Image search is an essential and user-friendly method to explore vast galleries of digital images. However, existing image search methods heavily rely on proximity measurements like tag matching or image similarity, requiring precise user inputs for satisfactory results. To meet the growing demand for a contemporary image search engine that enables accurate comprehension of users' search intentions, we introduce an innovative user intent expansion framework. Our framework leverages visual-language models to parse and compose multi-modal user inputs to provide more accurate and satisfying results. It comprises two-stage processes: 1) a parsing stage that incorporates a language parsing module with large language models to enhance the comprehension of textual inputs, along with a visual parsing module that integrates an interactive segmentation module to swiftly identify detailed visual elements?бн",Article,https://dl.acm.org/doi/abs/10.1145/3613904.3642185,2,ye2024contemporary, Image retrieval; Composed retrieval; Vision-language model; Multimodality; Large language model; Digital gallery
2024,Visual Informatics,Generative AI for visualization: State of the art and future directions,"Yilin Ye, Jianing Hao, Yihan Hou, Zhan Wang, Shishi Xiao, Yuyu Luo, Wei Zeng",Yilin Ye,English,"Generative AI (GenAI) has witnessed remarkable progress in recent years and demonstrated impressive performance in various generation tasks in different domains such as computer vision and computational design. Many researchers have attempted to integrate GenAI into visualization framework, leveraging the superior generative capacity for different operations. Concurrently, recent major breakthroughs in GenAI like diffusion model and large language model have also drastically increase the potential of GenAI4VIS. From a technical perspective, this paper looks back on previous visualization studies leveraging GenAI and discusses the challenges and opportunities for future research. Specifically, we cover the applications of different types of GenAI methods including sequence, tabular, spatial and graph generation techniques for different tasks of visualization which we summarize into four major stages?бн",Conference paper,https://dl.acm.org/doi/abs/10.1145/3641019,1,ye2024generative,None
2024,Proceedings of the CHI Conference on Human Factors in Computing Systems,PlantoGraphy: Incorporating iterative design process into generative artificial intelligence for landscape rendering,"Rong Huang, Haichuan Lin, Chuanzhang Chen, Kang Zhang, Wei Zeng",Rong Huang,English," Landscape renderings are realistic images of landscape sites, allowing stakeholders to perceive better and evaluate design ideas. While recent advances in Generative Artificial Intelligence (GAI (generative artificial intelligence)) enable automated generation of landscape renderings, the End to End (endtoend) methods are not compatible with common design processes, leading to insufficient alignment with design idealizations and limited cohesion of iterative landscape design. Informed by a formative study for comprehending design requirements, we present PlantoGraphy, an iterative design system that allows for interactive configuration of generative artificial intelligence models to accommodate human-centered design practice. A two-stage pipeline is incorporated: first, the concretization module transforms conceptual ideas into concrete scene layouts with a domain-oriented large language model; and?бн",Conference paper,https://dl.acm.org/doi/abs/10.1145/3613904.3642824,1,huang2024plantography,"Landscape rendering, large language model, scene graph, generative
artificial intelligence"
2024,Proceedings of the CHI Conference on Human Factors in Computing Systems,IntentTuner: An Interactive Framework for Integrating Human Intentions in Fine-tuning Text-to-Image Generative Models,"Xingchen Zeng, Ziyao Gao, Yilin Ye, Wei Zeng",Xingchen Zeng,English," Fine-tuning facilitates the adaptation of text-to-image generative models to novel concepts (e.g., styles and portraits), empowering users to forge creatively customized content. Recent efforts on fine-tuning focus on reducing training data and lightening computation overload but neglect alignment with user intentions, particularly in manual curation of multi-modal training data and intent-oriented evaluation. Informed by a formative study with fine-tuning practitioners for comprehending user intentions, we propose IntentTuner, an interactive framework that intelligently incorporates human intentions throughout each phase of the fine-tuning workflow. IntentTuner enables users to articulate training intentions with imagery exemplars and textual descriptions, automatically converting them into effective data augmentation strategies. Furthermore, IntentTuner introduces novel metrics to measure user intent alignment?бн",Conference paper,https://dl.acm.org/doi/abs/10.1145/3613904.3642165,1,zeng2024intenttuner,"text-to-image generative model, user intent understanding, and
data augmentation"
2023,IEEE Transactions on Visualization and Computer Graphics,TimeTuner: Diagnosing Time Representations for Time-Series Forecasting with Counterfactual Explanations,"Jianing Hao, Qing Shi, Yilin Ye, Wei Zeng",Jianing Hao,English,"Deep learning (DL) approaches are being increasingly used for time-series forecasting, with many efforts devoted to designing complex DL models. Recent studies have shown that the DL success is often attributed to effective data representations, fostering the fields of feature engineering and representation learning. However, automated approaches for feature learning are typically limited with respect to incorporating prior knowledge, identifying interactions among variables, and choosing evaluation metrics to ensure that the models are reliable. To improve on these limitations, this paper contributes a novel visual analytics framework, namely  TimeTuner , designed to help analysts understand how model behaviors are associated with localized correlations, stationarity, and granularity of time-series representations. The system mainly consists of the following two-stage technique: We first leverage counterfactual?бн",Article,https://dl.acm.org/doi/abs/10.1145/3615522.3615545,1,hao2023timetuner,"Time-series forecasting, counterfactual explanation, visual analytics"
2022,IEEE Transactions on Intelligent Transportation Systems,Large-Scale Urban Multiple-Modal Transport Evacuation Model for Mass Gathering Events Considering Pedestrian and Public Transit System,"Jincheng Jiang, Wei Tu, Hui Kong, Wei Zeng, Rui Zhang, Milan Konecny",Jincheng Jiang,English,"Mass gathering events occur frequently in urban regions. Not only serious traffic jams, but also safety risks are consequently caused. Although many evacuation strategies have been proposed, the spatiotemporal coordination issue of multiple-modal transport tools is not solved well to deal with the efficiency and safety risk during the traditional evacuations. This study presented a large-scale multi-modal transport macro-optimization evacuation model for urban mass gathering events. By taking full advantages of each kind of public transit vehicles and optimizing their spatiotemporal cooperation with pedestrian evacuation, our models can greatly improve the global evacuation efficiency. Experiments on a realistic event was carried to validate the proposed model. The numerical results demonstrated that, under the premise of no increasing additional vehicle supply, the efficiency of proposed multi-modal transport?бн",Article,https://ieeexplore.ieee.org/abstract/document/10297593/,1,jiang2022large,"Evacuation, multi-modal transport, multisource spatiotemporal data, macro-optimization, path planning"
2024,IEEE Transactions on Visualization and Computer Graphics,NFTracer: Tracing NFT Impact Dynamics in Transaction-flow Substitutive Systems with Visual Analytics,"Yifan Cao, Qing Shi, Lue Shen, Kani Chen, Yang Wang, Wei Zeng, Huamin Qu",Yifan Cao,English,"Impact dynamics are crucial for estimating the growth patterns of NFT projects by tracking the diffusion and decay of their relative appeal among stakeholders. Machine learning methods for impact dynamics analysis are incomprehensible and rigid in terms of their interpretability and transparency, whilst stakeholders require interactive tools for informed decision-making. Nevertheless, developing such a tool is challenging due to the substantial, heterogeneous NFT transaction data and the requirements for flexible, customized interactions. To this end, we integrate intuitive visualizations to unveil the impact dynamics of NFT projects. We first conduct a formative study and summarize analysis criteria, including substitution mechanisms, impact attributes, and design requirements from stakeholders. Next, we propose the Minimal Substitution Model to simulate substitutive systems of NFT projects that can be feasibly?бн",Article,https://ieeexplore.ieee.org/abstract/document/9901464/,0,cao2024nftracer,"Impact Dynamics Analysis, Non-Fungible Tokens (NFTs), NFT Transaction Data, Substitutive Systems, Visual
Analytics"
2024,Proceedings of the CHI Conference on Human Factors in Computing Systems,Make Interaction Situated: Designing User Acceptable Interaction for Situated Visualization in Public Environments,"Qian Zhu, Zhuo Wang, Wei Zeng, Wai Tong, Weiyue Lin, Xiaojuan Ma",Qian Zhu,English," Situated visualization blends data into the real world to fulfill individualsбп contextual information needs. However, interacting with situated visualization in public environments faces challenges posed by usersбп acceptance and contextual constraints. To explore appropriate interaction design, we first conduct a formative study to identify usersбп needs for data and interaction. Informed by the findings, we summarize appropriate interaction modalities with eye-based, hand-based and spatially-aware object interaction for situated visualization in public environments. Then, through an iterative design process with six users, we explore and implement interactive techniques for activating and analyzing with situated visualization. To assess the effectiveness and acceptance of these interactions, we integrate them into an AR prototype and conduct a within-subjects study in public scenarios using conventional hand-only?бн",Conference paper,https://ieeexplore.ieee.org/abstract/document/10534787/,0,zhu2024make,"Situated Visualization, Interactive Techniques, Social Acceptability"
2024,Extended Abstracts of the CHI Conference on Human Factors in Computing?бн,Understanding the Impact of Referent Design on Scale Perception in Immersive Data Visualization,"Yihan Hou, Hao Cui, Rongrong Chen, Wei Zeng",Yihan Hou,English," Referents are often used to enhance scale perception in immersive visualizations. Common referent designs include the considerations of referent layout (side-by-side vs. in-situ) and referent size (small vs. medium vs. large). This paper introduces a controlled user study to assess how different referent designs affect the efficiency and accuracy of scale perception across different data scales, on the performance of the size-matching task in the virtual environment. Our results reveal that in-situ layouts significantly enhance accuracy and confidence across various data scales, particularly with large referents. Linear regression analyses further confirm that in-situ layouts exhibit greater resilience to changes in data scale. For tasks requiring efficiency, medium-sized referents emerge as the preferred choice. Based on these findings, we offer design guidelines for selecting referent layouts and sizes in immersive?бн",Conference paper,https://dl.acm.org/doi/abs/10.1145/3613904.3642049,0,hou2024understanding,"Immersive Visualization, Referent Design, Scale Perception"
2024,arXiv preprint arXiv:2405.00351,Learning High-Quality Navigation and Zooming on Omnidirectional Images in Virtual Reality,"Zidong Cao, Zhan Wang, Yexin Liu, Yan-Pei Cao, Ying Shan, Wei Zeng, Lin Wang",Zidong Cao,English,"Viewing omnidirectional images (ODIs) in virtual reality (VR) represents a novel form of media that provides immersive experiences for users to navigate and interact with digital content. Nonetheless, this sense of immersion can be greatly compromised by a blur effect that masks details and hampers the user's ability to engage with objects of interest. In this paper, we present a novel system, called OmniVR, designed to enhance visual clarity during VR navigation. Our system enables users to effortlessly locate and zoom in on the objects of interest in VR. It captures user commands for navigation and zoom, converting these inputs into parameters for the Mobius transformation matrix. Leveraging these parameters, the ODI is refined using a learning-based algorithm. The resultant ODI is presented within the VR media, effectively reducing blur and increasing user engagement. To verify the effectiveness of our system, we first evaluate our algorithm with state-of-the-art methods on public datasets, which achieves the best performance. Furthermore, we undertake a comprehensive user study to evaluate viewer experiences across diverse scenarios and to gather their qualitative feedback from multiple perspectives. The outcomes reveal that our system enhances user engagement by improving the viewers' recognition, reducing discomfort, and improving the overall immersive experience. Our system makes the navigation and zoom more user-friendly.",Article,https://dl.acm.org/doi/abs/10.1145/3613905.3650783,0,cao2024learning,"Virtual reality, Image Processing and Computer Vision, Human-computer interaction"
2024,IEEE Transactions on Knowledge and Data Engineering,CheetahTraj: Efficient Visualization for Large Trajectory Dataset With Quality Guarantee,"Qiaomu Shen, Chaozu Zhang, Xiao Yan, Chuan Yang, Dan Zeng, Wei Zeng, Bo Tang",Qiaomu Shen,English,"Visualizing large-scale trajectory dataset is a core subroutine for many applications. However, rendering all trajectories could result in severe visual clutter and incur long visualization delays due to large data volume. Naively sampling the trajectories reduces visualization time but usually harms visual quality, i.e., the generated visualizations may look substantially different from the exact ones without sampling. In this paper, we propose CheetahTraj, a principled sampling framework that achieves both high visualization quality and low visualization latency. We first define the  visual quality function  measuring the similarity between two visualizations, based on which we formulate the quality optimal sampling problem (QOSP). To solve QOSP, we design the  V isual  Q uality  G uaranteed  S ampling algorithms, which reduce visual clutter while guaranteeing visual quality by considering both trajectory data distribution?бн",Article,https://arxiv.org/abs/2405.00351,0,shen2024cheetahtraj,Trajectory visualization; Interactive data exploration; Sampling
2024,2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR),Generating Virtual Reality Stroke Gesture Data from Out-of-Distribution Desktop Stroke Gesture Data,"Lin-Ping Yuan, Boyu Li, Jindong Wang, Huamin Qu, Wei Zeng",Lin-Ping Yuan,English,"This paper exploits ubiquitous desktop interaction data as an input source for generating virtual reality (VR) interaction data, which can benefit tasks like user behavior analysis and experience enhancement. Time-varying stroke gestures are selected as the primary focus because of their prevalence across various applications and their diverse patterns. The commonalities (e.g., features like velocity and curvature) between desktop and VR strokes allow the generation of additional dimensions (e.g., z vectors) in VR strokes. However, distribution shifts exist between different interaction environments (i.e., desktop vs. VR), and within the same interaction environment for different strokes by various users, making it challenging to build models capable of generalizing to unseen distributions. To address the challenges, we formulate the problem of generating VR strokes from desktop strokes as a conditional time series?бн",Conference paper,https://ieeexplore.ieee.org/abstract/document/10508806/,0,yuan2024generating,Human-centered computing; Virtual reality
2024,arXiv preprint arXiv:2403.03822,HoLens: A Visual Analytics Design for Higher-order Movement Modeling and Visualization,"Zezheng Feng, Fang Zhu, Hongjun Wang, Jianing Hao, ShuangHua Yang, Wei Zeng, Huamin Qu",Zezheng Feng,English,"Higher-order patterns reveal sequential multistep state transitions, which are usually superior to origin-destination analysis, which depicts only first-order geospatial movement patterns. Conventional methods for higher-order movement modeling first construct a directed acyclic graph (DAG) of movements, then extract higher-order patterns from the DAG. However, DAG-based methods heavily rely on the identification of movement keypoints that are challenging for sparse movements and fail to consider the temporal variants that are critical for movements in urban environments. To overcome the limitations, we propose HoLens, a novel approach for modeling and visualizing higher-order movement patterns in the context of an urban environment. HoLens mainly makes twofold contributions: first, we design an auto-adaptive movement aggregation algorithm that self-organizes movements hierarchically by considering spatial proximity, contextual information, and temporal variability; second, we develop an interactive visual analytics interface consisting of well-established visualization techniques, including the H-Flow for visualizing the higher-order patterns on the map and the higher-order state sequence chart for representing the higher-order state transitions. Two real-world case studies manifest that the method can adaptively aggregate the data and exhibit the process of how to explore the higher-order patterns by HoLens. We also demonstrate our approach's feasibility, usability, and effectiveness through an expert interview with three domain experts.",Article,https://ieeexplore.ieee.org/abstract/document/10494175/,0,feng2024holens,"Data Visualization, Movement Modeling, State
Sequence Visualization, Movement Visualization, Urban
Visual Analytics."
2024,None,Antarctica Storytelling: Creating Interactive Story Maps for Polar Regions with Graphic-Based Approach,"Liangwei Wang, Zhan Wang, Xi Zhao, Fugee Tsung, Wei Zeng",Liangwei Wang,English,"Although story maps have gained popularity for storytelling related to spatial information, existing story maps authoring tools often fall short in delivering diverse narrative forms and struggle to accurately render polar regions due to the limitations of tile-based mapping. In this work, we introduce a graphic-based method to address these challenges, developing a framework specifically designed for creating story maps for polar regions. Our key contribution lies in offering heuristic strategies for story map design, emphasizing their role in effectively visualizing and disseminating polar culture. This paper outlines essential design tasks for story map creation and introduces three pivotal narrative strategies: attention cue, linkage of map with other visual elements, and cartographic interaction. Additionally, we emphasize the significance of storyboard design, focusing on aspects such as logical sequencing, temporal order, map scale and granularity, and interactive design. To validate the effectiveness of our story map design framework, we develop several story map cases centered around the exploration history of Antarctica. These examples highlight the diversity and interactivity in the story maps produced through our methodology. Finally, we explore the challenges and limitations encountered in the process of creating story maps, and from these observations, we identify prospective areas for further research.",Conference paper,https://arxiv.org/abs/2403.03822,0,wang2024antarctica,"Storytelling ,Story Maps ,Map-based
Visual Narrative бд Antarctica"
2024,IEEE Transactions on Intelligent Transportation Systems,MetroBUX: A Topology-Based Visual Analytics for Bus Operational Uncertainty EXploration,"Shishi Xiao, Qing Shi, Lingdan Shao, Bo Du, Yang Wang, Qiaomu Shen, Wei Zeng",Shishi Xiao,English,"In the public transportation system, punctuality benefits both bus operation and passengersбп travel experience. However, uncertainty exists due to complex traffic conditions and heterogeneous driving behaviors. To analyze bus operational uncertainty, transport planners and bus operators need a tool that supports multi-granular modeling, spatio-temporal representation, and interactive exploration. To meet the requirement, we present MetroBUX, a visual analytics system for     us operational     ncertainty e    ploration. MetroBUX aligns daily bus trips and models stop-level uncertainty of bus arrival time. It has a consolidated interface with three main views: Map View for presenting the spatial distribution of uncertainty, Temporal View for tracking the evolution of uncertainty, and Trip View for inspecting uncertainty propagation. Specifically, MetroBUX enables integrated spatio-temporal analysis by connecting?бн",Article,https://www.researchsquare.com/article/rs-3942161/latest,0,xiao2024metrobux,"Bus operation, uncertainty modeling, uncertainty visualization, topology analysis, visual analytics"
2023,Proceedings of the 16th International Symposium on Visual Information?бн,LOOP Meditation: Enhancing Novice's VR Meditation Experience with Physical Movement,"Shihan Fu, Liangliang Qiang, Wei Zeng",Shihan Fu,English," Virtual reality (VR) and associated technologies have rapidly grew, creating new opportunities for improving mental health. In order to provide an immersive and concentrated meditation experience, this paper offers the idea of VR-assisted meditation, which integrates the advantages of VR technology with mindfulness techniques. The suggested technique, which is known as LOOP Meditation, is mainly aimed toward novice meditators and places a strong emphasis on the value of movement and breath awareness when meditating. Existing VR experiences and meditation applications sometimes ignore the value of including physical movement, which can improve mindful body sensations and maintain interest. By creating a software that incorporates body movement and breath sensing into virtual reality surroundings, LOOP Meditation addresses this gap. The LOOP Meditation design and implementation are?бн",Conference paper,https://ieeexplore.ieee.org/abstract/document/10379518/,0,fu2023loop,"Virtual reality, interaction design, meditation, wellness
"
2023,Proceedings of the 16th International Symposium on Visual Information?бн,Does Where You are Matter? A Visual Analytics System for COVID-19 Transmission Based on Social Hierarchical Perspective,"Jianing Hao, Xibin Jiang, Qing Shi, Wei Zeng",Jianing Hao,English," The COVID-19 pandemic requires multidisciplinary efforts to address its profound social and economic repercussions. Combining social hierarchical perspectives and a Multiple Coordinated View (MCV) visualization system, this paper depicts how social and physical residential environment shapes individualsбп infection risk during such pandemic. Through analyzing the travel records of 8000+ confirmed cases in spatial and temporal channels, we identify that there exists segregation of virus transmission among different social classes and individuals from deprived neighborhoods exhibit a higher risk of the virus infection. Leveraging our proposed interactive visualization system, policymakers and stakeholders can make more informed decisions to effectively manage and contain the spread of infectious pandemics like COVID-19.",Conference paper,https://dl.acm.org/doi/abs/10.1145/3615522.3615538,0,hao2023does,"neighborhood deprivation, visual analytics, COVID-19"
2023,Proceedings of the 16th International Symposium on Visual Information?бн,"The Rich, the Poor, and the Ugly: An Aesthetic-Perspective Assessment of NFT Values","Yihan Chen, Yilin Ye, Wei Zeng",Yihan Chen,English," The adoption of non-fungible tokens (NFTs) has revolutionized digital art transactions, providing artists with unprecedented opportunities to tokenize and monetize their generative creations, leading to increased scrutiny and demand within blockchain-oriented marketplaces. The pricing of NFT artworks, however, exhibits substantial variations within and across collections, influenced by various factors. This study aims to investigate the relationship between visual features and pricing, shedding light on the variations underlying the pricing of NFTs. First, measures of both computational aesthetics and visual complexity were applied to extract multi-faceted visual aesthetic features, encompassing aesthetic factors such as color and composition as well as complexity factors like entropy. Second, with extracted visual aesthetic features and preprocessed price data, the study proceeds to conduct correlation analysis within?бн",Conference paper,https://dl.acm.org/doi/abs/10.1145/3615522.3615528,0,chen2023rich,"Non-fungible tokens, computational aesthetics, statistical modeling"
2023,Proceedings of the 16th International Symposium on Visual Information?бн,Storytelling in Frozen Frontier: Exploring Graphic-Based Approach for Creating Interactive Story Maps in Antarctica,"Liangwei Wang, Zhan Wang, Xi Zhao, Wei Zeng",Liangwei Wang,English,"Story maps have been widely utilized to provide a visual and spatial framework for storytelling. However, existing story map tools have limitations in creating diverse narrative structures and providing interactive options, and cannot effectively render maps for polar regions due to tile-based mapping constraints. In this paper, we propose a graphic-based approach to overcome these challenges and develop a workflow for creating story maps specifically designed for polar regions. A primary contribution is to provide heuristic strategies for story map design and explore the potential of story maps in visualizing and disseminating polar culture. We summarize the main design tasks involved in story map creation and introduce three map-based visual narrative strategies, i.e., attention cue, linkage of map and other visual elements, and cartographic interaction. Additionally, we delve into the importance of storyboard design?бн",Conference paper,https://dl.acm.org/doi/abs/10.1145/3615522.3615524,0,wang2023storytelling,"Story maps, Storytelling, Map-based visual narrative"
2023,Proceedings of the 16th International Symposium on Visual Information?бн,NFTeller: Dual-centric Visual Analytics for Assessing Market Performance of NFT Collectibles,"Yifan Cao, Meng Xia, Kento Shigyo, Furui Cheng, Qianhang Yu, Xingxing Yang, Yang Wang, Wei Zeng, Huamin Qu",Yifan Cao,English," Non-fungible tokens (NFTs) have recently gained widespread popularity as an alternative investment. However, the lack of assessment criteria has caused intense volatility in NFT marketplaces. Identifying attributes impacting the market performance of NFT collectibles is crucial but challenging due to the massive amount of heterogeneous and multi-modal data in NFT transactions, e.g., social media texts, numerical trading data, and images. To address this challenge, we introduce an interactive dual-centric visual analytics system, NFTeller, to facilitate usersбп analysis. First, we collaborate with five domain experts to distill static and dynamic impact attributes and collect relevant data. Next, we derive six analysis tasks and develop NFTeller to present the evolution of NFT transactions and correlate NFTsбп market performance with impact attributes. Notably, we create an augmented chord diagram with a radial stacked?бн",Conference paper,https://dl.acm.org/doi/abs/10.1145/3615522.3615578,0,cao2023nfteller,"Impact Dynamics Analysis, Non-Fungible Tokens (NFTs), NFT Transaction Data, Substitutive Systems, Visual Analytics"
2023,arXiv preprint arXiv:2304.07999,Everyone Can Be Picasso? A Computational Framework into the Myth of Human versus AI Painting,"Yilin Ye, Rong Huang, Kang Zhang, Wei Zeng",Yilin Ye,English,"The recent advances of AI technology, particularly in AI-Generated Content (AIGC), have enabled everyone to easily generate beautiful paintings with simple text description. With the stunning quality of AI paintings, it is widely questioned whether there still exists difference between human and AI paintings and whether human artists will be replaced by AI. To answer these questions, we develop a computational framework combining neural latent space and aesthetics features with visual analytics to investigate the difference between human and AI paintings. First, with categorical comparison of human and AI painting collections, we find that AI artworks show distributional difference from human artworks in both latent space and some aesthetic features like strokes and sharpness, while in other aesthetic features like color and composition there is less difference. Second, with individual artist analysis of Picasso, we show human artists' strength in evolving new styles compared to AI. Our findings provide concrete evidence for the existing discrepancies between human and AI paintings and further suggest improvements of AI art with more consideration of aesthetics and human artists' involvement.",Article,https://arxiv.org/abs/2304.07999,0,ye2023everyone,None
2023,2023 IEEE International Conference on Big Data and Smart Computing (BigComp?бн,NFTeller: Dual Centric Visual Analytics of NFT Transactions,"Yifan Cao, Xingxing Yang, Meng Xia, Hongkun Liu, Kento Shigyo, Wei Zeng, Furui Cheng, Yang Wang, Qianhang Yu, Huamin Qu",Yifan Cao,English,"Non-fungible tokens (NFTs) can certify the authenticity and scarcity of digital assets on the blockchain. There is an urgent need to identify impact attributes from various potential factors and further evaluate NFT collectibles. Nevertheless, the task is challenging due to the massive amount of heterogeneous and multi-modal data (e.g., social media text, numerical transaction data, and images) in NFT transactions. To this end, we present an interactive visual analytics system, NFTeller, that provides a dual-centric perspective analysis of NFT transactions. The system i) summarizes the temporal evolution and correlation of transaction patterns and dynamic impact attributes of NFT collection projects; ii) presents an augmented chord diagram with a radial stacked bar chart for exploring the co-collected projects and co-occurring whale accounts. We derive in-depth insights from case studies on a real data set to evaluate the?бн",Conference paper,https://ieeexplore.ieee.org/abstract/document/10066688/,0,cao2023nfteller,"Non-fungible tokens (NFTs), Blockchain, Visual analytics"
